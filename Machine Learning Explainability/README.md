# Machine Learning Explainability

1. Use Cases for Model Insights:
Why and when do you need insights?

2. Permutation Importance:
What features does your model think are important?

3. Partial Plots:
How does each feature affect your predictions?

4. SHAP Values:
Understand individual predictions.

5. Advanced Uses of SHAP Values:
Aggregate SHAP values for even more detailed model insights.

![Abdulrahman Khalid - Machine Learning Explainability](https://user-images.githubusercontent.com/76521677/212492327-13abe7c2-a663-4782-8006-5a534bf1b919.png)


